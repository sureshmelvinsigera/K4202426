What is a Pod in Kubernetes?
In this section, we will delve deeper into the core Kubernetes concept called a Pod.

With Kubernetes, our primary goal is to deploy our applications, which are in the form of containers, onto the worker
nodes within a Kubernetes cluster. Kubernetes doesn't deploy these containers directly onto the worker nodes. Instead, a
container is encapsulated into a Kubernetes object named Pod.

A Pod is a single instance of an application and is the smallest object we can create in Kubernetes. Pods generally have
a one-to-one relationship with containers.

For example, if we have one Pod on a worker node and it starts receiving a significant amount of traffic, we will need
to add new Pods to scale our application. This means that to scale up, we create new Pods, and to scale down, we delete
the Pods. If traffic continues to grow, we scale our application by adding more Pods.

It's important to note that we cannot have multiple containers of the same kind in a single Pod. For instance, if you
have a Pod with an Nginx container serving static content or acting as a proxy, you cannot scale by adding more Nginx
containers inside the same Pod. Instead, you should scale by adding more Pods. Having two Nginx containers in a single
Pod serving the same purpose is not recommended.

However, we can have multi-container Pods in exceptional cases. In 99% of scenarios, one Pod will contain one container.
But in the rare 1% of cases, we can have multiple containers within a single Pod, provided they are not of the same
kind.

For example, in a Kubernetes cluster, you might have a Pod with an Nginx container serving static content and another
helper container. These helper containers, known as sidecar containers, perform auxiliary tasks such as pulling data
required by the main container from another service or pushing data collected from the main container. Sidecar
containers can also act as proxies.

The advantage of multi-container Pods is that the containers can easily communicate with each other as they share the
same network and storage space. However, multi-container Pods are a rare use case, and we will focus on the core
fundamental relationship, which is one Pod to one container.

In Docker, we package the application or any executable along with all its dependencies into a Docker image. We then
create an instance of this image, which we call a container. We treat this container like a virtual machine. These
containers can communicate with each other using IP addresses or service names if they are on the same network. For
example, for one container to talk to another, it needs to know the other's IP address to send requests and receive
responses.

To clarify with an example, in the Docker world, each Docker container represents an isolated environment and gets an IP
address. Similarly, in Kubernetes, each Pod represents an isolated environment, and the containers within the Pod
represent processes. Each Pod is assigned an IP address, allowing multiple containers to run within the Pod.

For instance, on your machine, you might run a Spring Boot application and a MongoDB database as separate processes.
These processes can communicate with each other using localhost and the appropriate port numbers. For example, your
Spring application might connect to a MongoDB database using the local host port 27017. Similarly, within a Pod,
containers can communicate with each other using localhost without needing to know the IP address. They just need to
know the port number.

To sum up, this is how a Pod works: it contains one or more containers, usually just one main application container and
possibly some helper containers. In the next part of this section, we will play with Pods hands-on to make things
clearer with practical examples.

Thank you, and Iâ€™ll see you in the next lecture!